{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naive Bayes on Political Text\n",
    "\n",
    "In this notebook we use Naive Bayes to explore and classify political data. See the `README.md` for full details. You can download the required DB from the shared dropbox or from blackboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "import nltk\n",
    "import random\n",
    "import numpy as np\n",
    "from collections import Counter, defaultdict\n",
    "\n",
    "import pandas as pd\n",
    "from nltk.corpus import stopwords\n",
    "from string import punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connect to database\n",
    "convention_db = sqlite3.connect(\"2020_Conventions.db\")\n",
    "convention_cur = convention_db.cursor()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 1: Exploratory Naive Bayes\n",
    "\n",
    "We'll first build a NB model on the convention data itself, as a way to understand what words distinguish between the two parties. This is analogous to what we did in the \"Comparing Groups\" class work. First, pull in the text \n",
    "for each party and prepare it for use in Naive Bayes.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conventions\n"
     ]
    }
   ],
   "source": [
    "# Identify table names in the database\n",
    "convention_cur.execute(\"SELECT name FROM sqlite_master WHERE type='table';\")\n",
    "\n",
    "# Print table names in database\n",
    "tables = convention_cur.fetchall()\n",
    "for table in tables:\n",
    "    print(table[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        party  night           speaker  speaker_count   time  \\\n",
      "0  Democratic      4           Unknown              1  00:00   \n",
      "1  Democratic      4         Speaker 1              1  00:33   \n",
      "2  Democratic      4         Speaker 2              1  00:59   \n",
      "3  Democratic      4  Kerry Washington              1  01:07   \n",
      "4  Democratic      4    Bernie Sanders              1  01:18   \n",
      "\n",
      "                                                text text_len  \\\n",
      "0  Skip to content The Company Careers Press Free...      127   \n",
      "1  I’m here by calling the full session of the 48...       41   \n",
      "2  Every four years, we come together to reaffirm...       17   \n",
      "3  We fight for a more perfect union because we a...       28   \n",
      "4  We must come together to defeat Donald Trump, ...       22   \n",
      "\n",
      "                                                file  \n",
      "0  www_rev_com_blog_transcripts2020-democratic-na...  \n",
      "1  www_rev_com_blog_transcripts2020-democratic-na...  \n",
      "2  www_rev_com_blog_transcripts2020-democratic-na...  \n",
      "3  www_rev_com_blog_transcripts2020-democratic-na...  \n",
      "4  www_rev_com_blog_transcripts2020-democratic-na...  \n"
     ]
    }
   ],
   "source": [
    "# Select top 5 rows to analyze format and column names\n",
    "query_results = convention_cur.execute(\n",
    "                            '''\n",
    "                            SELECT * FROM conventions\n",
    "                            LIMIT 5\n",
    "                            ''')\n",
    "df = pd.DataFrame(query_results.fetchall(), columns=[desc[0] for desc in query_results.description])\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Punctuation\n",
    "punctuation = set(punctuation) # speeds up comparison\n",
    "\n",
    "# Stopwords\n",
    "sw = stopwords.words(\"english\")\n",
    "\n",
    "# Removes stopwords\n",
    "def remove_stop(tokens):\n",
    "    \n",
    "    tokens = [word for word in tokens if word not in sw]\n",
    "    \n",
    "    return(tokens)\n",
    " \n",
    "# Removes punctuation\n",
    "def remove_punctuation(text, punct_set=punctuation): \n",
    "    \n",
    "    return(\"\".join([ch for ch in text if ch not in punct_set]))\n",
    "\n",
    "# Tokenizes the test\n",
    "def tokenize(text):     \n",
    "    \n",
    "    return text.split()\n",
    "\n",
    "# Applies the pipeline\n",
    "def prepare_pipeline(text): \n",
    "    \n",
    "    text = str.lower(text)\n",
    "    text = remove_punctuation(text)\n",
    "    tokens = tokenize(text)\n",
    "    tokens = remove_stop(tokens)\n",
    "    \n",
    "    return(' '.join(tokens))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize empty list\n",
    "convention_data = []\n",
    "\n",
    "# Select text and party from conventions table\n",
    "query_results = convention_cur.execute(\n",
    "                            '''\n",
    "                            SELECT text, party FROM conventions\n",
    "                            ''')\n",
    "\n",
    "# For each row in query results:\n",
    "for row in query_results :\n",
    "    text, party = row\n",
    "    # Apply text to pipeline\n",
    "    tokenized_text = prepare_pipeline(text)\n",
    "    # Append list to convention_data\n",
    "    convention_data.append([tokenized_text, party])\n",
    "    \n",
    "# The first element in the sublist is the cleaned and tokenized\n",
    "# text in a single string. The second element of the sublist\n",
    "# is the party. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at some random entries and see if they look right. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['jon honor devotion showing returning citizens forgotten believe person made god purpose continue give americans including former inmates best chance build new life achieve american dream great american dream i’d like ask john richard say words',\n",
       "  'Republican'],\n",
       " ['navy senate liaison used carry bags overseas trips', 'Democratic'],\n",
       " ['support defend', 'Republican'],\n",
       " ['son scranton claymont wilmington become one consequential vice presidents american history accolade nonetheless rest firmly behind legacy husband father grandfather grateful nation thanks vice president joseph r biden jr lifetime service behalf united states america',\n",
       "  'Democratic'],\n",
       " ['care environment', 'Democratic']]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random.choices(convention_data,k=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If that looks good, we now need to make our function to turn these into features. In my solution, I wanted to keep the number of features reasonable, so I only used words that occur at least `word_cutoff` times. Here's the code to test that if you want it. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "With a word cutoff of 5, we have 2391 as features in the model.\n"
     ]
    }
   ],
   "source": [
    "word_cutoff = 5\n",
    "\n",
    "tokens = [w for t, p in convention_data for w in t.split()]\n",
    "\n",
    "word_dist = nltk.FreqDist(tokens)\n",
    "\n",
    "feature_words = set()\n",
    "\n",
    "for word, count in word_dist.items() :\n",
    "    if count > word_cutoff :\n",
    "        feature_words.add(word)\n",
    "        \n",
    "print(f\"With a word cutoff of {word_cutoff}, we have {len(feature_words)} as features in the model.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_features(text,fw) :\n",
    "    \"\"\"Given some text, this returns a dictionary holding the\n",
    "       feature words.\n",
    "       \n",
    "       Args: \n",
    "            * text: a piece of text in a continuous string. Assumes\n",
    "            text has been cleaned and case folded.\n",
    "            * fw: the *feature words* that we're considering. A word \n",
    "            in `text` must be in fw in order to be returned. This \n",
    "            prevents us from considering very rarely occurring words.\n",
    "        \n",
    "       Returns: \n",
    "            A dictionary with the words in `text` that appear in `fw`. \n",
    "            Words are only counted once. \n",
    "            If `text` were \"quick quick brown fox\" and `fw` = {'quick','fox','jumps'},\n",
    "            then this would return a dictionary of \n",
    "            {'quick' : True,\n",
    "             'fox' :    True}\n",
    "        \n",
    "    \"\"\"\n",
    "    \n",
    "    # Initialize empty dictionary\n",
    "    ret_dict = {}\n",
    "    \n",
    "    # Split text into tokens\n",
    "    tokens = text.split()\n",
    "    \n",
    "    # For each token:\n",
    "    for word in tokens:\n",
    "        # If word is found in fw, then add to dictionary with value True\n",
    "        if word in fw:\n",
    "            ret_dict[word] = True\n",
    "    \n",
    "    # Return dictionary\n",
    "    return(ret_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert(len(feature_words)>0)\n",
    "assert(conv_features(\"donald is the president\",feature_words)==\n",
    "       {'donald':True,'president':True})\n",
    "assert(conv_features(\"some people in america are citizens\",feature_words)==\n",
    "                     {'people':True,'america':True,\"citizens\":True})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we'll build our feature set. Out of curiosity I did a train/test split to see how accurate the classifier was, but we don't strictly need to since this analysis is exploratory. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "featuresets = [(conv_features(text,feature_words), party) for (text, party) in convention_data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(20220507)\n",
    "random.shuffle(featuresets)\n",
    "\n",
    "test_size = 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5\n"
     ]
    }
   ],
   "source": [
    "test_set, train_set = featuresets[:test_size], featuresets[test_size:]\n",
    "classifier = nltk.NaiveBayesClassifier.train(train_set)\n",
    "print(nltk.classify.accuracy(classifier, test_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most Informative Features\n",
      "                   china = True           Republ : Democr =     25.8 : 1.0\n",
      "                   votes = True           Democr : Republ =     23.8 : 1.0\n",
      "             enforcement = True           Republ : Democr =     21.5 : 1.0\n",
      "                 destroy = True           Republ : Democr =     19.2 : 1.0\n",
      "                freedoms = True           Republ : Democr =     18.2 : 1.0\n",
      "                 climate = True           Democr : Republ =     17.8 : 1.0\n",
      "                supports = True           Republ : Democr =     17.1 : 1.0\n",
      "                   crime = True           Republ : Democr =     16.1 : 1.0\n",
      "                   media = True           Republ : Democr =     14.9 : 1.0\n",
      "                 beliefs = True           Republ : Democr =     13.0 : 1.0\n",
      "               countries = True           Republ : Democr =     13.0 : 1.0\n",
      "                 defense = True           Republ : Democr =     13.0 : 1.0\n",
      "                    isis = True           Republ : Democr =     13.0 : 1.0\n",
      "                 liberal = True           Republ : Democr =     13.0 : 1.0\n",
      "                religion = True           Republ : Democr =     13.0 : 1.0\n",
      "                   trade = True           Republ : Democr =     12.7 : 1.0\n",
      "                    flag = True           Republ : Democr =     12.1 : 1.0\n",
      "               greatness = True           Republ : Democr =     12.1 : 1.0\n",
      "                 abraham = True           Republ : Democr =     11.9 : 1.0\n",
      "                  defund = True           Republ : Democr =     11.9 : 1.0\n",
      "                    drug = True           Republ : Democr =     10.9 : 1.0\n",
      "              department = True           Republ : Democr =     10.9 : 1.0\n",
      "               destroyed = True           Republ : Democr =     10.9 : 1.0\n",
      "                   enemy = True           Republ : Democr =     10.9 : 1.0\n",
      "               amendment = True           Republ : Democr =     10.3 : 1.0\n"
     ]
    }
   ],
   "source": [
    "classifier.show_most_informative_features(25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### My Observations\n",
    "\n",
    "The Naive Bayes classifier performed with 50% accuracy, which is no better than flipping a coin to determine which political party the text comes from. With that being said, the classifier still gives us valuable information by analyzing he most informative features. Out of the top 25 most informative features, 23 of them come from Republicans. The most informative features out of this list from the Republican party are 'china', 'enforcement', 'destroy', 'freedoms', 'supports', and 'crime'. The most informative features out of this list from the Democratic party are 'votes' and 'climate'. \n",
    "\n",
    "It is interesting that the majority of the most informative features belong to the Republican party. Though this is helpful for identifying both parties because if one of these features does appear, then we can be more confident that the text comes from a Republican speaker, and if these features do NOT appear, then we can be more confident that the text comes from a Democratic speaker."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Classifying Congressional Tweets\n",
    "\n",
    "In this part we apply the classifer we just built to a set of tweets by people running for congress\n",
    "in 2018. These tweets are stored in the database `congressional_data.db`. That DB is funky, so I'll\n",
    "give you the query I used to pull out the tweets. Note that this DB has some big tables and \n",
    "is unindexed, so the query takes a minute or two to run on my machine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connect to database\n",
    "cong_db = sqlite3.connect(\"congressional_data.db\")\n",
    "cong_cur = cong_db.cursor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Query results\n",
    "results = cong_cur.execute(\n",
    "        '''\n",
    "           SELECT DISTINCT \n",
    "                  cd.candidate, \n",
    "                  cd.party,\n",
    "                  tw.tweet_text\n",
    "           FROM candidate_data cd \n",
    "           INNER JOIN tweets tw ON cd.twitter_handle = tw.handle \n",
    "               AND cd.candidate == tw.candidate \n",
    "               AND cd.district == tw.district\n",
    "           WHERE cd.party in ('Republican','Democratic') \n",
    "               AND tw.tweet_text NOT LIKE '%RT%'\n",
    "        ''')\n",
    "\n",
    "results = list(results) # Just to store it, since the query is time consuming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize empty list\n",
    "tweet_data = []\n",
    "\n",
    "# For each row in query results:\n",
    "for row in results :\n",
    "    candidate, party, tweet_text = row\n",
    "    # Apply text to pipeline\n",
    "    text = str(tweet_text)\n",
    "    tokenized_text = prepare_pipeline(text)\n",
    "    # Append list to tweet_data\n",
    "    tweet_data.append([tokenized_text, party])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are a lot of tweets here. Let's take a random sample and see how our classifer does. I'm guessing it won't be too great given the performance on the convention speeches..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(20201014)\n",
    "\n",
    "tweet_data_sample = random.choices(tweet_data,k=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here's our (cleaned) tweet: bearlier today spoke house floor abt protecting health care women praised ppmarmonte work central coast httpstcowqgtrzt7vv\n",
      "Actual party is Democratic and our classifer says Republican.\n",
      "\n",
      "Here's our (cleaned) tweet: bgo tribe rallytogether httpstco0nxutfl9l5\n",
      "Actual party is Democratic and our classifer says Democratic.\n",
      "\n",
      "Here's our (cleaned) tweet: bapparently trump thinks easy students overwhelmed crushing burden debt pay student loans trumpbudget httpstcockyqo5t0qh\n",
      "Actual party is Democratic and our classifer says Republican.\n",
      "\n",
      "Here's our (cleaned) tweet: bwexe2x80x99re grateful first responders rescue personnel firefighters police volunteers working tirelessly keep people safe provide muchneeded help putting lives linennhttpstcoezpv0vmiz3\n",
      "Actual party is Republican and our classifer says Republican.\n",
      "\n",
      "Here's our (cleaned) tweet: bletxe2x80x99s make even greater kag xf0x9fx87xbaxf0x9fx87xb8 httpstcoy9qozd5l2z\n",
      "Actual party is Republican and our classifer says Republican.\n",
      "\n",
      "Here's our (cleaned) tweet: bwe 1hr cavs tie series 22 im allin216 repbarbaralee scared roadtovictory\n",
      "Actual party is Democratic and our classifer says Republican.\n",
      "\n",
      "Here's our (cleaned) tweet: bcongrats belliottsd new gig sd city hall glad continue servexe2x80xa6 httpstcofkvmw3cqdi\n",
      "Actual party is Democratic and our classifer says Republican.\n",
      "\n",
      "Here's our (cleaned) tweet: bwe really close 3500 raised toward match right whoot thatxe2x80x99s 7000 nonmath majors room xf0x9fx98x82 help us get httpstcotu34c472sd httpstcoqsdqkypsmc\n",
      "Actual party is Democratic and our classifer says Republican.\n",
      "\n",
      "Here's our (cleaned) tweet: btoday comment period potusxe2x80x99s plan expand offshore drilling opened public 60 days march 9 share oppose proposed program directly trump administration comments made email mail httpstcobaaymejxqn\n",
      "Actual party is Democratic and our classifer says Republican.\n",
      "\n",
      "Here's our (cleaned) tweet: bcelebrated icseastlaxe2x80x99s 22 years eastside commitment amp saluted community leaders last nightxe2x80x99s awards dinner httpstco7v7gh8givb\n",
      "Actual party is Democratic and our classifer says Republican.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Estimate party for tweet_data_sample\n",
    "for tweet, party in tweet_data_sample :\n",
    "    # First find features\n",
    "    tweet_features = conv_features(tweet, feature_words)\n",
    "    # Apply classifer\n",
    "    estimated_party = classifier.classify(tweet_features)\n",
    "    \n",
    "    # Print estimated party samples\n",
    "    print(f\"Here's our (cleaned) tweet: {tweet}\")\n",
    "    print(f\"Actual party is {party} and our classifer says {estimated_party}.\")\n",
    "    print(\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we've looked at it some, let's score a bunch and see how we're doing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dictionary of counts by actual party and estimated party. \n",
    "# first key is actual, second is estimated\n",
    "parties = ['Republican','Democratic']\n",
    "results = defaultdict(lambda: defaultdict(int))\n",
    "\n",
    "for p in parties:\n",
    "    for p1 in parties:\n",
    "        results[p][p1] = 0\n",
    "\n",
    "num_to_score = 10000\n",
    "random.shuffle(tweet_data)\n",
    "\n",
    "# For each row in tweet_data:\n",
    "for idx, row in enumerate(tweet_data):\n",
    "    tweet, party = row    \n",
    "    # First find features\n",
    "    tweet_features = conv_features(tweet, feature_words)\n",
    "    # Apply classifier\n",
    "    estimated_party = classifier.classify(tweet_features)\n",
    "   \n",
    "    results[party][estimated_party] += 1\n",
    "    \n",
    "    if idx > num_to_score : \n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(<function __main__.<lambda>()>,\n",
       "            {'Republican': defaultdict(int,\n",
       "                         {'Republican': 3605, 'Democratic': 673}),\n",
       "             'Democratic': defaultdict(int,\n",
       "                         {'Republican': 4723, 'Democratic': 1001})})"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reflections\n",
    "This Naive Bayes classifier does not do very well at estimating the political party from congressional tweets. The classifier is 3605/4278 = 84% accurate at classifying Republican tweets and 1001/5724 = 18% accurate at classifying Democratic congressional tweets, with an overall accuracy of 4606/10002 = 46%. This might have to do with the fact that a majority of the most informative features from the training data belonged to the Republican party. Because of this, the model over-classifies the party as Republican. \n",
    "\n",
    "To improve this model, I would suggest making sure the training dataset is balanced. Additionally, the feature_words might need to be altered. More records could be beneficial to aid in the training of the model, as the pattern of Democratic speeches could be better analyzed."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
